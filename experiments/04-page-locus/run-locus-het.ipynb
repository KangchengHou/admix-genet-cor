{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e27b8e0c-f4ef-455a-a2c5-118d13289158",
   "metadata": {},
   "source": [
    "# Loci analysis\n",
    "1. Take the top SNPs for each significant loci\n",
    "2. Test the heterogeneity score.\n",
    "3. Aggregate over multiple traits and multiple regions and show QQ-plot\n",
    "\n",
    "`page-gwas.tsv` is downloaded from GWAS catalog https://www.ebi.ac.uk/gwas/publications/31217584 (Download catalog data)\n",
    "\n",
    "**Links below are not used in this notebook but I preserve these just in case**\n",
    "\n",
    "Also see \n",
    "- https://github.com/gokceneraslan/opentargets-genetics-python\n",
    "- https://community.opentargets.org/t/how-to-access-finngen-gwas-data-using-the-open-targets-genetics-portal-api/254/4\n",
    "- https://api.genetics.opentargets.org/graphql/schema\n",
    "\n",
    "!wget https://static-content.springer.com/esm/art%3A10.1038%2Fs41586-019-1310-4/MediaObjects/41586_2019_1310_MOESM3_ESM.xlsx -O page-supp-tables.xlsx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b9a3a36-9d68-463b-b58a-cb58a5932b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The lab_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext lab_black\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext lab_black\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import admix\n",
    "import dask\n",
    "import dask.array as da\n",
    "from tqdm import tqdm\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from admix.data import quantile_normalize\n",
    "import submitit\n",
    "\n",
    "import admix_genet_cor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b713c7e7-1fc6-4f7e-9f37-9903688f66e7",
   "metadata": {},
   "source": [
    "# Process GWAS hits from PAGE study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d32e6ce5-efff-4813-85f6-2430f675ae06",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUPP_TABLE_URL = \"https://www.dropbox.com/s/jck2mhjby2ur55j/supp_tables.xlsx?dl=1\"\n",
    "trait_info = pd.read_excel(SUPP_TABLE_URL, sheet_name=\"trait-info\")\n",
    "trait_list = trait_info[\"trait\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f328f0e-0979-4c9a-8dde-6094456d6653",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_assoc = pd.read_csv(\"./page-gwas.tsv\", sep=\"\\t\")\n",
    "df_assoc = (\n",
    "    df_assoc[\n",
    "        [\n",
    "            \"DISEASE/TRAIT\",\n",
    "            \"INITIAL SAMPLE SIZE\",\n",
    "            \"REGION\",\n",
    "            \"SNPS\",\n",
    "            \"CHR_ID\",\n",
    "            \"CHR_POS\",\n",
    "            \"P-VALUE\",\n",
    "            \"STUDY ACCESSION\",\n",
    "        ]\n",
    "    ]\n",
    "    .dropna(subset=[\"CHR_POS\"])\n",
    "    .astype({\"CHR_POS\": int})\n",
    ")\n",
    "\n",
    "df_assoc = df_assoc.loc[df_assoc.CHR_ID.isin(np.arange(1, 23).astype(str))]\n",
    "# NOTE: the 24 + 2 additional traits are waist-hip ratio for males and females\n",
    "\n",
    "# convert trait_id\n",
    "gwas_catalog_name2id = {\n",
    "    row[\"GWAS catalog name\"]: row[\"trait\"] for _, row in trait_info.iterrows()\n",
    "}\n",
    "df_assoc.insert(\n",
    "    0, \"trait_id\", df_assoc[\"DISEASE/TRAIT\"].apply(lambda x: gwas_catalog_name2id[x])\n",
    ")\n",
    "df_assoc[\"CHR_ID\"] = df_assoc[\"CHR_ID\"].astype(int)\n",
    "df_assoc = (\n",
    "    df_assoc.sort_values([\"trait_id\", \"CHR_ID\", \"CHR_POS\"])\n",
    "    .drop_duplicates([\"trait_id\", \"CHR_ID\", \"CHR_POS\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "df_assoc.index = (\n",
    "    df_assoc[\"trait_id\"]\n",
    "    + \":\"\n",
    "    + df_assoc[\"CHR_ID\"].astype(str)\n",
    "    + \":\"\n",
    "    + df_assoc[\"CHR_POS\"].astype(str)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d6cd2dc-5ca1-4894-be95-39db786f80f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dapgen\n",
    "from os.path import join\n",
    "\n",
    "PFILE_DIR = \"/u/project/pasaniuc/pasaniucdata/admixture/projects/PAGE-QC/01_dataset/out/aframr/imputed\"\n",
    "SAMPLE_INFO_PATH = \"/u/project/pasaniuc/pasaniucdata/admixture/projects/PAGE-QC/01_dataset/out/aframr/sample_info.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96447c4c-a6af-471a-8ed7-c7a05a6295a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_locus_hetero(trait, out, duffy_covar=False):\n",
    "    df_assoc_trait = df_assoc[df_assoc.trait_id == trait].copy()\n",
    "\n",
    "    # format phenotype and covariates\n",
    "\n",
    "    dset = admix.dataset.read_dataset(\n",
    "        join(PFILE_DIR, \"chr1\"),\n",
    "        indiv_info=SAMPLE_INFO_PATH,\n",
    "        n_anc=2,\n",
    "    )\n",
    "    dset_assoc = dset[:, ~np.isnan(dset.indiv[trait]).values]\n",
    "    covar_cols = [\"age\", \"sex\", \"study\"] + [f\"geno_EV{i}\" for i in range(1, 11)]\n",
    "\n",
    "    df_pheno = dset_assoc.indiv[[trait]].copy()\n",
    "    df_covar = dset_assoc.indiv[covar_cols].copy()\n",
    "    # create study dummies variables\n",
    "    study_dummies = pd.get_dummies(df_covar[\"study\"], drop_first=True)\n",
    "    study_dummies.columns = [f\"study_dummy_{s}\" for s in study_dummies.columns]\n",
    "    df_covar = pd.concat([df_covar, study_dummies], axis=1)\n",
    "    df_covar = df_covar.drop(columns=[\"study\"])\n",
    "\n",
    "    # special case for duffy SNPs, include the duffy SNPs in the covariate\n",
    "    if duffy_covar:\n",
    "        # find closest SNPs to Duffy SNP (GRCH38: 1:159204893)\n",
    "        duffy_snp_loc = np.argmin(np.abs(dset_assoc.snp.POS - 159204893))\n",
    "        assert dset_assoc.snp.CHROM.iloc[duffy_snp_loc] == 1\n",
    "        duffy_lanc = dset_assoc[duffy_snp_loc].lanc.sum(axis=[0, 2]).compute()\n",
    "        df_covar[\"duffy_lanc\"] = duffy_lanc\n",
    "\n",
    "    for col in df_pheno.columns:\n",
    "        df_pheno[col] = admix.data.quantile_normalize(df_pheno[col])\n",
    "\n",
    "    for col in df_covar.columns:\n",
    "        df_covar[col] = admix.data.quantile_normalize(df_covar[col])\n",
    "\n",
    "    for chrom in range(1, 23):\n",
    "        # subset df_assoc\n",
    "        df_assoc_trait_chrom = df_assoc_trait[df_assoc_trait.CHR_ID == chrom]\n",
    "\n",
    "        # subset dset\n",
    "        dset = admix.dataset.read_dataset(\n",
    "            join(PFILE_DIR, f\"chr{chrom}\"),\n",
    "            indiv_info=SAMPLE_INFO_PATH,\n",
    "            n_anc=2,\n",
    "        )\n",
    "        dset = dset[\n",
    "            dset.snp.POS.isin(df_assoc_trait_chrom.CHR_POS.values).values,\n",
    "            df_pheno.index.values,\n",
    "        ]\n",
    "        dset.persist()\n",
    "\n",
    "        apa = dset.allele_per_anc()\n",
    "        af = dset.af_per_anc()\n",
    "\n",
    "        for snp_i in tqdm(range(dset.n_snp)):\n",
    "            p_het, model_het = admix_genet_cor.test_snp_het(\n",
    "                apa[snp_i, :, :], df_pheno.values, df_covar.values\n",
    "            )\n",
    "            p_assoc, model_assoc = admix_genet_cor.test_snp_assoc(\n",
    "                apa[snp_i, :, :], df_pheno.values, df_covar.values\n",
    "            )\n",
    "            snp_idx = f\"{trait}:{dset.snp.CHROM[snp_i]}:{dset.snp.POS[snp_i]}\"\n",
    "            df_assoc_trait.loc[snp_idx, [\"EUR_af\", \"AFR_af\"]] = (\n",
    "                af[snp_i, 0],\n",
    "                af[snp_i, 1],\n",
    "            )\n",
    "\n",
    "            df_assoc_trait.loc[\n",
    "                snp_idx,\n",
    "                [\n",
    "                    \"assoc_pval\",\n",
    "                    \"HET_pval\",\n",
    "                    \"EUR_beta\",\n",
    "                    \"AFR_beta\",\n",
    "                    \"EUR_beta_stderr\",\n",
    "                    \"AFR_beta_stderr\",\n",
    "                ],\n",
    "            ] = [\n",
    "                p_assoc,\n",
    "                p_het,\n",
    "                model_het.params[1],\n",
    "                model_het.params[2],\n",
    "                model_het.bse[1],\n",
    "                model_het.bse[2],\n",
    "            ]\n",
    "    df_assoc_trait.to_csv(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa0e8be7-1513-4969-9a22-6c34b1a235a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:02<00:00,  8.61it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 14.03it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.18it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 13.27it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 10.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.78it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.40it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 12.34it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "submit_locus_hetero(\n",
    "    \"total_wbc_cnt\", \"out/locus_hetero/total_wbc_cnt.duffy_covar.csv\", True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "019fd055-ed3f-434f-9613-e4d0b4ccb2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "executor = submitit.SgeExecutor(folder=\"./submitit-logs\")\n",
    "\n",
    "executor.update_parameters(\n",
    "    time_min=20,\n",
    "    memory_g=16,\n",
    "    setup=[\n",
    "        \"export PATH=~/project-pasaniuc/software/miniconda3/bin:$PATH\",\n",
    "        \"export PYTHONNOUSERSITE=True\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "jobs = executor.map_array(\n",
    "    submit_locus_hetero,\n",
    "    trait_list,\n",
    "    [f\"out/locus_hetero/{trait}.csv\" for trait in trait_list],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
