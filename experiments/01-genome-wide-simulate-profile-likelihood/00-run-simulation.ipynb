{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c71feda-724a-49b0-96e9-ad0a7075d76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext lab_black\n",
    "\n",
    "import numpy as np\n",
    "import dapgen\n",
    "import pandas as pd\n",
    "import dask.array as da\n",
    "import itertools\n",
    "import submitit\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import admix_genet_cor\n",
    "from admix_genet_cor import calc_snp_prior_var\n",
    "import pandas as pd\n",
    "import admix\n",
    "from os.path import join\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc8e62e-5355-40f4-b76f-017d25b8cba7",
   "metadata": {},
   "source": [
    "# Overview of simulation studies\n",
    "- p_causal: 0.001, 1.0\n",
    "- var_g: 1.0\n",
    "- var_e: 1.0\n",
    "- gamma: 0.5, 0.8, 1.0\n",
    "- set of SNPs: simulate from the imputed SNPs, the non-zero effects are simulated from SNPs with allele frequencies > 0.005 in both populations.\n",
    "\n",
    "From S-LDXR paper: \n",
    "```\n",
    "In these simulations, we randomly selected 10% of the SNPs to be causal in each population, with 80% of causal variants in each population shared with the other population, and sampled perfectly correlated causal effect sizes for shared causal variants using Eq. In these simulations, we set the variance of causal effect size of each SNP j in both populations to be proportional to $[p_{j,max}(1−p_{j,max})]^\\alpha$, where pj,max is the maximum MAF of SNP j in the two populations.  We set α to − 0.38, as previously estimated for 25 UK Biobank diseases \n",
    "and complex traits in ref.\n",
    "```\n",
    "\n",
    "Here, we simulate from the imputed SNPs the non-zero effects are simulated from SNPs with allele frequencies > 0.005 in both populations. And from these, we sample 1% of causal effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b78dd1f9-7e8d-4c0f-ad57-553122ea893b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "\n",
    "DATA_ROOT_DIR = (\n",
    "    \"/u/project/pasaniuc/pasaniucdata/admixture/projects/PAGE-QC/01-dataset/out/aframr\"\n",
    ")\n",
    "GRM_DIR = \"/u/scratch/k/kangchen/admix-grm/rho-model\"\n",
    "\n",
    "# define the simulation parameters\n",
    "df_simulate_params = pd.DataFrame(\n",
    "    [\n",
    "        params\n",
    "        for params in itertools.product(\n",
    "            #             [0.1, 0.25, 0.5],\n",
    "            [0.25],\n",
    "            [0.00001, 0.0001, 0.001, 0.01],\n",
    "            [0.9, 0.95, 1.0],\n",
    "            [\"mafukb\"],\n",
    "        )\n",
    "    ],\n",
    "    columns=[\"hsq\", \"pcausal\", \"cor\", \"hermodel\"],\n",
    ")\n",
    "df_simulate_params[\"out_prefix\"] = df_simulate_params.apply(\n",
    "    lambda row: f\"out/pheno/hsq-{row.hsq}-pcausal-{np.format_float_positional(row.pcausal)}\"\n",
    "    f\"-cor-{row.cor}-hermodel-{row.hermodel}\",\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b23a3f5-4ebc-4b32-9cbf-e6b9dec8a060",
   "metadata": {},
   "source": [
    "# Step 1: Simulate phenotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54e09928-ccda-4f45-9749-c0d06d72cf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_simulate_pheno(\n",
    "    hsq: float,\n",
    "    pcausal: float,\n",
    "    cor: float,\n",
    "    hermodel: str,\n",
    "    out_prefix: str,\n",
    "    n_sim=500,\n",
    "):\n",
    "    \"\"\"\n",
    "    her_model: one of [uniform, gcta, ldak]\n",
    "\n",
    "    \"\"\"\n",
    "    np.random.seed(admix.utils.str2int(out_prefix))\n",
    "    N_ANC = 2\n",
    "    pfile_list = [f\"{DATA_ROOT_DIR}/imputed/chr{chrom}\" for chrom in range(1, 23)]\n",
    "\n",
    "    geno = []\n",
    "    lanc = []\n",
    "    df_indiv = None\n",
    "    df_snp = []\n",
    "    df_snp_info = []\n",
    "\n",
    "    # read data\n",
    "    for pfile in pfile_list:\n",
    "\n",
    "        this_geno, this_df_snp, this_df_indiv = dapgen.read_pfile(\n",
    "            pfile, phase=True, snp_chunk=4000\n",
    "        )\n",
    "        this_lanc = admix.io.read_lanc(pfile + \".lanc\").dask(snp_chunk=4000)\n",
    "        this_df_snp_info = pd.read_csv(pfile + \".snp_info\", sep=\"\\t\")\n",
    "        assert np.all(this_df_snp_info.SNP == this_df_snp.index.values)\n",
    "\n",
    "        if df_indiv is None:\n",
    "            df_indiv = this_df_indiv\n",
    "        else:\n",
    "            assert df_indiv.equals(\n",
    "                df_indiv\n",
    "            ), \".psam should be consistent for all pfiles\"\n",
    "        geno.append(this_geno)\n",
    "        lanc.append(this_lanc)\n",
    "        df_snp_info.append(this_df_snp_info)\n",
    "\n",
    "    # concatenate\n",
    "    geno = da.concatenate(geno, axis=0)\n",
    "    lanc = da.concatenate(lanc, axis=0)\n",
    "    df_snp_info = pd.concat(df_snp_info).reset_index(drop=True)\n",
    "\n",
    "    snp_prior_var = calc_snp_prior_var(df_snp_info, hermodel)\n",
    "\n",
    "    # simulate effects\n",
    "    snp_subset = np.where(\n",
    "        df_snp_info.EUR_FREQ.between(0.005, 0.995)\n",
    "        & df_snp_info.AFR_FREQ.between(0.005, 0.995)\n",
    "    )[0]\n",
    "\n",
    "    # sub-sample SNPs from `geno`, `lanc`, `df_snp_info`, `snp_prior_var`\n",
    "    n_eff_snp = len(snp_subset)\n",
    "    geno = geno[snp_subset, :, :]\n",
    "    lanc = lanc[snp_subset, :, :]\n",
    "    df_snp_info = df_snp_info.iloc[snp_subset, :]\n",
    "    snp_prior_var = snp_prior_var[snp_subset]\n",
    "\n",
    "    beta = np.zeros((n_eff_snp, N_ANC, n_sim))  # (n_snp, n_anc, n_sim)\n",
    "    n_causal = int(n_eff_snp * pcausal)\n",
    "    print(f\"n_causal: {n_causal}\")\n",
    "    for i_sim in range(n_sim):\n",
    "        cau = sorted(\n",
    "            np.random.choice(np.arange(n_eff_snp), size=n_causal, replace=False)\n",
    "        )\n",
    "\n",
    "        i_beta = np.random.multivariate_normal(\n",
    "            mean=[0.0, 0.0],\n",
    "            cov=np.array([[1, cor], [cor, 1]]) / n_causal,\n",
    "            size=n_causal,\n",
    "        )\n",
    "\n",
    "        i_beta = i_beta * np.sqrt(snp_prior_var[cau])[:, None]\n",
    "\n",
    "        for i_anc in range(N_ANC):\n",
    "            beta[cau, i_anc, i_sim] = i_beta[:, i_anc]\n",
    "\n",
    "    sim = admix_genet_cor.simulate_quant_pheno(\n",
    "        geno=geno, lanc=lanc, hsq=hsq, beta=beta, n_sim=n_sim\n",
    "    )\n",
    "    np.savez_compressed(out_prefix + \".beta\", sim[\"beta\"])\n",
    "    df_snp_info.to_csv(out_prefix + \".beta_info.tsv.gz\", index=False, sep=\"\\t\")\n",
    "\n",
    "    df_pheno = pd.DataFrame(\n",
    "        sim[\"pheno\"],\n",
    "        index=df_indiv.index,\n",
    "        columns=[f\"SIM_{i}\" for i in range(n_sim)],\n",
    "    )\n",
    "    df_pheno.to_csv(out_prefix + \".pheno.tsv.gz\", index=True, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27a2381d-6e93-4073-afe3-ad3c07ae3139",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/project/pasaniuc/kangchen/software/submitit-sge/submitit/core/core.py:699: UserWarning: Received an empty job array\n",
      "  warnings.warn(\"Received an empty job array\")\n"
     ]
    }
   ],
   "source": [
    "executor = submitit.SgeExecutor(folder=\"./submitit-logs\")\n",
    "\n",
    "executor.update_parameters(\n",
    "    time_min=1400,\n",
    "    memory_g=64,\n",
    "    #     queue=\"highp\",\n",
    "    setup=[\n",
    "        \"export PATH=~/project-pasaniuc/software/miniconda3/bin:$PATH\",\n",
    "        \"export PYTHONNOUSERSITE=True\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "df_todo_params = df_simulate_params[\n",
    "    ~df_simulate_params.apply(\n",
    "        lambda x: os.path.exists(x.out_prefix + \".pheno.tsv.gz\"), axis=1\n",
    "    )\n",
    "]\n",
    "jobs = executor.map_array(\n",
    "    submit_simulate_pheno,\n",
    "    df_todo_params.hsq,\n",
    "    df_todo_params.pcausal,\n",
    "    df_todo_params.cor,\n",
    "    df_todo_params.hermodel,\n",
    "    df_todo_params.out_prefix,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fadf06-d0bd-497e-9870-5923706bcf7a",
   "metadata": {},
   "source": [
    "# Step 2: GCTA Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f33bf83c-64ae-4d83-94f4-ab09615e23c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define GRM parameters\n",
    "df_grm_params = pd.DataFrame(\n",
    "    [\n",
    "        params\n",
    "        for params in itertools.product(\n",
    "            [\"hm3\", \"imputed\"],\n",
    "            [\"mafukb\"],\n",
    "            [0.005],\n",
    "        )\n",
    "    ],\n",
    "    columns=[\n",
    "        \"snpset\",\n",
    "        \"hermodel\",\n",
    "        \"maf\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "df_grm_params[\"grm_prefix\"] = df_grm_params.apply(\n",
    "    lambda p: f\"{p.snpset}.{p.hermodel}.{str(p.maf)[2:]}\",\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "df_estimate_params = df_simulate_params.copy()\n",
    "df_estimate_params[\"estimate_out_dir\"] = df_estimate_params.apply(\n",
    "    lambda row: row.out_prefix.replace(\"pheno\", \"gcta-estimate\"), axis=1\n",
    ")\n",
    "\n",
    "df_estimate_params = df_estimate_params.merge(\n",
    "    pd.DataFrame(\n",
    "        [\n",
    "            params\n",
    "            for params in itertools.product(\n",
    "                np.arange(100),\n",
    "                (np.linspace(0, 1, 21) * 100).astype(int),\n",
    "            )\n",
    "        ],\n",
    "        columns=[\"sim_i\", \"rho\"],\n",
    "    ),\n",
    "    how=\"cross\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9012adc-47ff-4a1e-8662-b4ada7776ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 jobs to be done.\n"
     ]
    }
   ],
   "source": [
    "# define GRM parameters\n",
    "df_grm_params = pd.DataFrame(\n",
    "    [\n",
    "        params\n",
    "        for params in itertools.product(\n",
    "            [\"hm3\", \"imputed\"],\n",
    "            [\"mafukb\"],\n",
    "            [0.005],\n",
    "        )\n",
    "    ],\n",
    "    columns=[\n",
    "        \"snpset\",\n",
    "        \"hermodel\",\n",
    "        \"maf\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "df_grm_params[\"grm_prefix\"] = df_grm_params.apply(\n",
    "    lambda p: f\"{p.snpset}.{p.hermodel}.{str(p.maf)[2:]}\",\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "df_estimate_params = df_simulate_params.copy()\n",
    "df_estimate_params[\"estimate_out_dir\"] = df_estimate_params.apply(\n",
    "    lambda row: row.out_prefix.replace(\"pheno\", \"gcta-estimate\"), axis=1\n",
    ")\n",
    "\n",
    "df_estimate_params = df_estimate_params.merge(\n",
    "    pd.DataFrame(\n",
    "        [\n",
    "            params\n",
    "            for params in itertools.product(\n",
    "                np.arange(0, 100),\n",
    "                (np.linspace(0, 1, 21) * 100).astype(int),\n",
    "                df_grm_params[\"grm_prefix\"].values,\n",
    "            )\n",
    "        ],\n",
    "        columns=[\"sim_i\", \"rho\", \"grm_prefix\"],\n",
    "    ),\n",
    "    how=\"cross\",\n",
    ")\n",
    "\n",
    "# filter todo jobs\n",
    "df_estimate_params = df_estimate_params[\n",
    "    ~df_estimate_params.apply(\n",
    "        lambda x: os.path.exists(\n",
    "            os.path.join(\n",
    "                x.estimate_out_dir, x.grm_prefix, f\"sim_{x.sim_i}.rho{x.rho}.hsq\"\n",
    "            )\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "]\n",
    "print(f\"{len(df_estimate_params)} jobs to be done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7b8fb16-bd8b-469a-bbf0-6dc7b6270cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def submit_gcta_estimate(pheno: str, grm_prefix: str, sim_i: int, out_dir: str):\n",
    "#     \"\"\"\n",
    "#     Run estimate for all rho values\n",
    "#     \"\"\"\n",
    "#     # compile phenotype and covariates\n",
    "#     df_pheno = pd.read_csv(pheno, delim_whitespace=True, index_col=0)\n",
    "#     df_pheno = pd.DataFrame(\n",
    "#         {\n",
    "#             \"FID\": df_pheno.index.values,\n",
    "#             \"IID\": df_pheno.index.values,\n",
    "#             \"trait\": df_pheno[f\"SIM_{sim_i}\"].values,\n",
    "#         }\n",
    "#     )\n",
    "\n",
    "#     os.makedirs(os.path.join(out_dir, grm_prefix), exist_ok=True)\n",
    "\n",
    "#     ### fit different rho\n",
    "#     rho_list = (np.linspace(0, 1, 21) * 100).astype(int)\n",
    "\n",
    "#     for rho in rho_list:\n",
    "#         grm = join(GRM_DIR, grm_prefix, f\"rho{rho}\")\n",
    "#         out_prefix = os.path.join(out_dir, grm_prefix, f\"sim_{sim_i}.rho{rho}\")\n",
    "#         if not os.path.exists(out_prefix + \".hsq\"):\n",
    "#             admix.tools.gcta.reml(\n",
    "#                 grm_path=grm,\n",
    "#                 df_pheno=df_pheno,\n",
    "#                 out_prefix=out_prefix,\n",
    "#                 n_thread=2,\n",
    "#             )\n",
    "\n",
    "\n",
    "def submit_gcta_estimate(\n",
    "    pheno: str, grm_prefix: str, rho: int, sim_i: int, out_dir: str\n",
    "):\n",
    "    \"\"\"\n",
    "    Run estimate for a single rho values\n",
    "    \"\"\"\n",
    "    # compile phenotype and covariates\n",
    "    df_pheno = pd.read_csv(pheno, delim_whitespace=True, index_col=0)\n",
    "    df_pheno = pd.DataFrame(\n",
    "        {\n",
    "            \"FID\": df_pheno.index.values,\n",
    "            \"IID\": df_pheno.index.values,\n",
    "            \"trait\": df_pheno[f\"SIM_{sim_i}\"].values,\n",
    "        }\n",
    "    )\n",
    "    os.makedirs(os.path.join(out_dir, grm_prefix), exist_ok=True)\n",
    "\n",
    "    ### fit different rho\n",
    "    grm = join(GRM_DIR, grm_prefix, f\"rho{rho}\")\n",
    "    out_prefix = os.path.join(out_dir, grm_prefix, f\"sim_{sim_i}.rho{rho}\")\n",
    "\n",
    "    admix.tools.gcta.reml(\n",
    "        grm_path=grm,\n",
    "        df_pheno=df_pheno,\n",
    "        out_prefix=out_prefix,\n",
    "        n_thread=4,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d300e26-f613-4816-83f4-6b5abefd9b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "executor = submitit.SgeExecutor(folder=\"./submitit-logs\")\n",
    "\n",
    "executor.update_parameters(\n",
    "    time_min=180,\n",
    "    #     time_min=75,\n",
    "    memory_g=15,\n",
    "    #         queue=\"highp\",\n",
    "    setup=[\n",
    "        \"export PATH=~/project-pasaniuc/software/miniconda3/bin:$PATH\",\n",
    "        \"export PYTHONNOUSERSITE=True\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "jobs = executor.map_array(\n",
    "    submit_gcta_estimate,\n",
    "    (df_estimate_params[\"out_prefix\"] + \".pheno.tsv.gz\"),\n",
    "    df_estimate_params.grm_prefix,\n",
    "    df_estimate_params.rho,\n",
    "    df_estimate_params.sim_i,\n",
    "    df_estimate_params.estimate_out_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a38dcc-433a-4389-a547-37f86d07265f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
